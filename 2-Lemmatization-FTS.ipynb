{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task objective:\n",
    "\n",
    "- Define an ES analyzer for Polish texts containing:\n",
    "    - standard tokenizer\n",
    "    - synonym filter with alternative forms for months, e.g. wrzesień, wrz, IX.\n",
    "    - lowercase filter\n",
    "    - Morfologik-based lemmatizer\n",
    "    - lowercase filter (looks strange, but Morfologi produces capitalized base forms for proper names, so we have to lowercase them once more).\n",
    "- Define another analyzer for Polish, without the synonym filter.\n",
    "- Define an ES index for storing the contents of the corpus from lab 1 using both analyzers. Use different names for the fields analyzed with a different pipeline.\n",
    "- Load the data to the ES index.\n",
    "- Determine the number of documents containing the word styczeń (in any form) including and excluding the synonyms.\n",
    "- Download the QA pairs for the FIQA dataset.\n",
    "- Compute NDCG@5 for the QA dataset (the test subset) for the following setusp:\n",
    "    - synonyms enabled and disabled,\n",
    "    - lemmatization in the query enabled and disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milenabiernacka/anaconda3/envs/PJN/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from elasticsearch_dsl import Search, Document, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer with synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_with_synonyms_settings = {\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"polish_with_synonyms_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\": [\n",
    "                    \"lowercase\",\n",
    "                    \"polish_months_synonyms\",\n",
    "                    \"morfologik_stem\",\n",
    "                    \"lowercase\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"filter\": {\n",
    "            \"polish_months_synonyms\": {\n",
    "                \"type\": \"synonym\",\n",
    "                \"synonyms\": [\n",
    "                    \"styczeń, sty, I\",\n",
    "                    \"luty, lut, II\",\n",
    "                    \"marzec, mar, III\",\n",
    "                    \"kwiecień, kwi, IV\",\n",
    "                    \"maj, V\",\n",
    "                    \"czerwiec, cze, VI\",\n",
    "                    \"lipiec, lip, VII\",\n",
    "                    \"sierpień, sie, VIII\",\n",
    "                    \"wrzesień, wrz, IX\",\n",
    "                    \"październik, paź, X\",\n",
    "                    \"listopad, lis, XI\",\n",
    "                    \"grudzień, gru, XII\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_with_synonyms_mappings = {\n",
    "    \"properties\": {\n",
    "        \"text\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"polish_with_synonyms_analyzer\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'index_with_synonyms'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# tworzenie indeksu\n",
    "es.indices.create(index=\"index_with_synonyms\", \n",
    "                  settings=index_with_synonyms_settings,\n",
    "                  mappings=index_with_synonyms_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer without synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_without_synonyms_settings = {\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"polish_without_synonyms_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\": [\n",
    "                    \"lowercase\",\n",
    "                    \"morfologik_stem\",\n",
    "                    \"lowercase\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_without_synonyms_mappings = {\n",
    "    \"properties\": {\n",
    "        \"text\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"polish_without_synonyms_analyzer\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'index_without_synonyms'})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tworzenie indeksu\n",
    "es.indices.create(index=\"index_without_synonyms\", \n",
    "                  settings=index_without_synonyms_settings,\n",
    "                  mappings=index_without_synonyms_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset FIQA-PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "df = pd.DataFrame(dataset['corpus'])\n",
    "df_text = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Nie mówię, że nie podoba mi się też pomysł szk...\n",
       "1        Tak więc nic nie zapobiega fałszywym ocenom po...\n",
       "2        Nigdy nie możesz korzystać z FSA dla indywidua...\n",
       "3        Samsung stworzył LCD i inne technologie płaski...\n",
       "4        Oto wymagania SEC: Federalne przepisy dotycząc...\n",
       "                               ...                        \n",
       "57633    >Cóż, po pierwsze, drogi to coś więcej niż hob...\n",
       "57634    Tak, robią. Na dotacje dla firm farmaceutyczny...\n",
       "57635    >To bardzo smutne, że nie rozumiesz ludzkiej n...\n",
       "57636    „Czy Twój CTO pozwolił dużej grupie użyć „„adm...\n",
       "57637    Zapewnienie rządowi większej kontroli nad dyst...\n",
       "Name: text, Length: 57638, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data to ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteruje po tekstach i indeksuje je do obydwu stworzonych indeksow: z synonimami i bez\n",
    "for idx, text in enumerate(df_text):\n",
    "    document = {\n",
    "        \"text\": text,\n",
    "    }\n",
    "    es.index(index=\"index_with_synonyms\", id=idx, document=document)\n",
    "    es.index(index=\"index_without_synonyms\", id=idx, document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully uploaded.\n"
     ]
    }
   ],
   "source": [
    "# sprawdzenie czy liczba dokumentow zapisanych w ES i index_with_synonyms rowna sie ilosci tekstow z datasetu\n",
    "if es.count(index=\"index_with_synonyms\")['count'] == len(dataset['corpus']['text']):\n",
    "    print(\"Data successfully uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully uploaded.\n"
     ]
    }
   ],
   "source": [
    "# sprawdzenie czy liczba dokumentow zapisanych w ES i index_without_synonyms rowna sie ilosci tekstow z datasetu\n",
    "if es.count(index=\"index_without_synonyms\")['count'] == len(dataset['corpus']['text']):\n",
    "    print(\"Data successfully uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638\n",
      "57638\n"
     ]
    }
   ],
   "source": [
    "# sprawdzanie liczby zaindeksowanych tesktow\n",
    "print(es.count(index=\"index_with_synonyms\")['count'])\n",
    "print(es.count(index=\"index_without_synonyms\")['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching number of documents containing `styczeń` word with and without synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents including 'styczen' with synonyms: 10000\n"
     ]
    }
   ],
   "source": [
    "# Zapytanie z synonimami\n",
    "query_styczen_with_synonyms = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\": {\n",
    "                \"query\": \"styczeń\",\n",
    "                \"analyzer\": \"polish_with_synonyms_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Wykonanie zapytania\n",
    "response = es.search(index=\"index_with_synonyms\", body=query_styczen_with_synonyms)\n",
    "\n",
    "# Liczba pasujących dokumentów\n",
    "total_hits = response[\"hits\"][\"total\"][\"value\"]\n",
    "print(\"Number of documents including 'styczen' with synonyms: \" + str(total_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents including 'styczen' without synonyms: 329\n"
     ]
    }
   ],
   "source": [
    "# Zapytanie bez synonimow\n",
    "query_styczen_without_synonyms = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\": {\n",
    "                \"query\": \"styczeń\",\n",
    "                \"analyzer\": \"polish_without_synonyms_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Wykonanie zapytania\n",
    "response = es.search(index=\"index_without_synonyms\", body=query_styczen_without_synonyms)\n",
    "\n",
    "# Liczba pasujących dokumentów\n",
    "total_hits = response[\"hits\"][\"total\"][\"value\"]\n",
    "print(\"Number of documents including 'styczen' without synonyms: \" + str(total_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usunięcie wszystkich dokumentów w danym indeksie -  na wypadek gdybym znowu uruchomiła wczytywanie dokumnetow :/ \n",
    "# es.delete_by_query(index=\"polish_analyzer\", body={\"query\": {\"match_all\": {}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset FIQA-PL-QRELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_QA = load_dataset(\"clarin-knext/fiqa-pl-qrels\")\n",
    "dataset_QA_test = dataset_QA['test']\n",
    "df_qa_test = pd.DataFrame(dataset_QA['test'])\n",
    "\n",
    "dataset_queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
    "df_queries = pd.DataFrame(dataset_queries['queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Rozpoczęcie nowego biznesu online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>„Dzień roboczy” i „termin płatności” rachunków</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Nowy właściciel firmy – Jak działają podatki d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>4102</td>\n",
       "      <td></td>\n",
       "      <td>Jak mogę ustalić, czy moja stopa zwrotu jest „...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>3566</td>\n",
       "      <td></td>\n",
       "      <td>Gdzie mogę kupić akcje, jeśli chcę zainwestowa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>94</td>\n",
       "      <td></td>\n",
       "      <td>Wykorzystywanie punktów kart kredytowych do op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>2551</td>\n",
       "      <td></td>\n",
       "      <td>Jak znaleźć tańszą alternatywę dla tradycyjnej...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>2399</td>\n",
       "      <td></td>\n",
       "      <td>Skąd strony internetowe uzyskują informacje o ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id title                                               text\n",
       "0        0        Co jest uważane za wydatek służbowy w podróży ...\n",
       "1        4        Wydatki służbowe - ubezpieczenie samochodu pod...\n",
       "2        5                        Rozpoczęcie nowego biznesu online\n",
       "3        6           „Dzień roboczy” i „termin płatności” rachunków\n",
       "4        7        Nowy właściciel firmy – Jak działają podatki d...\n",
       "...    ...   ...                                                ...\n",
       "6643  4102        Jak mogę ustalić, czy moja stopa zwrotu jest „...\n",
       "6644  3566        Gdzie mogę kupić akcje, jeśli chcę zainwestowa...\n",
       "6645    94        Wykorzystywanie punktów kart kredytowych do op...\n",
       "6646  2551        Jak znaleźć tańszą alternatywę dla tradycyjnej...\n",
       "6647  2399        Skąd strony internetowe uzyskują informacje o ...\n",
       "\n",
       "[6648 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja obliczajaca metryke NDCG przyjmujaca wynik jako parametr\n",
    "K = 5\n",
    "\n",
    "def calc_ndcg_k(scores):\n",
    "    if len(scores) != K : Exception(\"Invalid scores arr size, != 5\")\n",
    "    dcg = np.sum(scores / np.log2(np.arange(2, len(scores) + 2)))\n",
    "    idcg = np.sum(sorted(scores, reverse=True) / np.log2(np.arange(2, len(scores) + 2)))\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "    return ndcg\n",
    "\n",
    "df_queries_text = df_queries['text']\n",
    "arr = np.array([0.0 for i in range(K)])\n",
    "tmp = set()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 versions of NDCG@5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapytanie z synonimami\n",
    "query_ndcg_with_synonyms = {\n",
    "        \"match\": {\n",
    "            \"text\":{\n",
    "                \"query\":\"\",\n",
    "                \"analyzer\":\"polish_with_synonyms_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# zapytanie bez lematyzacji\n",
    "query_ndcg_without_lemmatizaion = {\n",
    "        \"match\": {\n",
    "            \"text\":{\n",
    "                \"query\":\"\",\n",
    "                \"analyzer\":\"standard\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# zapytanie bez synonimow\n",
    "query_ndcg_without_synonyms = {\n",
    "        \"match\": {\n",
    "            \"text\":{\n",
    "                \"query\":\"\",\n",
    "                \"analyzer\":\"polish_without_synonyms_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja obliczajaca ndcg dla podanego indexu i zapytania\n",
    "def ndcg_for_index(index, query):\n",
    "    ndcg = 0\n",
    "    iterator = 0\n",
    "\n",
    "    for query_id in df_qa_test['query-id'].unique(): # iteruje po unikalnych query_id\n",
    "        query_up = df_queries[df_queries['_id'] == str(query_id)].iloc[0]['text'] # pobieram query (jako tekst) do pasujacego query_id\n",
    "        query['match']['text']['query'] = query_up # update'uje zapytanie do obliczania ndcg o znalezione query\n",
    "        resp = es.search(index=index, query=query) # znajduje wyniki zapytania\n",
    "        corpus_ids = df_qa_test[df_qa_test['query-id'] == query_id]['corpus-id'] # znajduje wszystkie corpus_id dla odpowiadajacego query_id\n",
    "        \n",
    "        # przechowuje w tmp indeksy, ktore pasuja do zapytania\n",
    "        tmp = set() \n",
    "        for idx in corpus_ids:\n",
    "            _id = df[df['_id'] == str(idx)].index.tolist()[0]\n",
    "            tmp.add(_id)\n",
    "            \n",
    "        # przegladam K wynikow z ES i sprawdzam czy sa one w tmp. Jeśli są -> ocena 3, jeśli nie -> 0. \n",
    "        for idx, val in enumerate(resp['hits']['hits'][:K]):\n",
    "            _id = np.float64(val['_id'])\n",
    "            if _id in tmp:\n",
    "                arr[idx] = 3\n",
    "            else:\n",
    "                arr[idx] = 0\n",
    "\n",
    "        # obliczam NDCG\n",
    "        ndcg += calc_ndcg_k(arr)\n",
    "        iterator += 1\n",
    "        mean_ndcg = ndcg / iterator\n",
    "    return (\"NDCG: \"+ str(ndcg), \"Mean NDCG: \" + str(mean_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NDCG: 172.96008915896866', 'Mean NDCG: 0.2669137178379146')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_for_index(\"index_with_synonyms\", query_ndcg_with_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NDCG: 172.19452861340906', 'Mean NDCG: 0.2657322972429152')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_for_index(\"index_without_synonyms\", query_ndcg_without_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworze indeks do wersji z lematyzacja\n",
    "index_without_lemmatization_mappings = {\n",
    "    \"properties\": {\n",
    "        \"text\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"standard\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'index_without_lemmatization'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index = \"index_without_lemmatization\", mappings=index_without_lemmatization_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NDCG: 324.0', 'Mean NDCG: 0.5')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ndcg_for_index(\"index_without_lemmatization\", query_ndcg_without_lemmatizaion)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16323c91b843e809beaa456fc31b90062c2b6877cc09dc9168e9867538bda6d2"
  },
  "kernelspec": {
   "display_name": "NLP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
