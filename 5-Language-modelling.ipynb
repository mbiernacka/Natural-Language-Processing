{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modelling\n",
    "\n",
    "Objectives:\n",
    "\n",
    "- Read the documentation of Language modelling in the Transformers library.\n",
    "\n",
    "- Download three Polish models from the Huggingface repository. These should be regular language models, which were not fine-tuned. E.g. HerBERT and papuGaPT2 are good examples.\n",
    "\n",
    "- Devise a method to test if the langage model understands Polish cases. E.g. testing for nominal case could be expressed as \"Warszawa to największe [MASK]\", and the masked word should be in nominative case. Create sentences for each case.\n",
    "\n",
    "- Devise a method to test long-range relationships such as gender. E.e. you can use two verbs with masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences.\n",
    "\n",
    "- Check if the model captures real-world knolwedge. For instance a sentence \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences.\n",
    "\n",
    "- Check zero-shot learning capabilites of the models. Provide at least 5 sentences with different sentiment for the following scheme: \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie [MASK]\" Try different prompts, to see if they make any difference.\n",
    "\n",
    "- Take into accout the fact, that causal language models such as PapuGaPT2 or plT5, will only generate continuations of the sentenes, so the examples have to be created according to that paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoModelWithLMHead\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download three Polish models from the Huggingface repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline function creates an instance of a pipeline for a specific NLP task. You provide the task name (e.g., \"text-generation\") and, optionally, the name or path of the model you want to use. The library then handles the details of loading the appropriate model and configuring it for the specified task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading papuGaPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load papuGA model directly\n",
    "tokenizer_papuga = AutoTokenizer.from_pretrained(\"dkleczek/papuGaPT2\")\n",
    "model_papuga = AutoModelForCausalLM.from_pretrained(\"dkleczek/papuGaPT2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading HerBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.sso.sso_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.sso.sso_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "tokenizer_herbert = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "model_herbert = AutoModel.from_pretrained(\"allegro/herbert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading XLM-RoBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_xlm = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model_xlm = AutoModel.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devise a method to test if the langage model understands Polish cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example sentences in different cases for HerBERT and XLM models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominative = [\n",
    "    \"Pies to najlepszy <mask> człowieka.\",\n",
    "    \"Widzę na niebie kolorową <mask>.\"\n",
    "]\n",
    "\n",
    "genitive = [\n",
    "    \"Jednak mój brat nie zbił <mask> w samochodzie.\",\n",
    "    \"Ta ksiązka nalezy do <mask>.\"\n",
    "]\n",
    "\n",
    "dative = [\n",
    "    \"Sprzedałam mój rower młodszemu <mask>.\",\n",
    "    \"Fajnie jest pomagać <mask> w potrzebie.\"\n",
    "]\n",
    "\n",
    "accusative = [\n",
    "    \"Widzę wysokie <mask> na horyzoncie.\",\n",
    "    \"Uwielabim, gdy moja mama przygotowuje <mask>.\"\n",
    "]\n",
    "\n",
    "instrumental = [\n",
    "    \"Ostatnio częściej zdarza mi się pisać kolorowym <mask>.\",\n",
    "    \"Najchętniej jezdzę do szkoły <mask>.\"\n",
    "]\n",
    "\n",
    "locative = [\n",
    "    \"Nie mogę przestać marzyć o <mask>.\",\n",
    "    \"Bardzo długo toczyły się rozmowy o <mask>.\"\n",
    "]\n",
    "\n",
    "vocative = [\n",
    "    \"Ej <mask>, o której wrócisz?\",\n",
    "    \"Bądź ostrozny na drodze, <mask>.\"\n",
    "]\n",
    "\n",
    "cases = [nominative, genitive, dative, accusative, instrumental, locative, vocative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm = \"xlm-roberta-base\"\n",
    "herbert = \"allegro/herbert-base-cased\"\n",
    "papuga = \"dkleczek/papuGaPT2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cases1(model, sentences):\n",
    "    # Wybierzmy jeden model, na przykład xlm-roberta-base\n",
    "    model_name = model\n",
    "\n",
    "    # Pipeline do predykcji maski\n",
    "    unmasker = pipeline('fill-mask', model=model_name)\n",
    "\n",
    "    # Test predykcji dla jednego modelu\n",
    "    print(f\"Testing {model_name}:\\n\")\n",
    "    for sentence in sentences:\n",
    "        # Wygeneruj predykcje\n",
    "        predictions = unmasker(sentence)\n",
    "        \n",
    "        completed_sentence = sentence.replace('<mask>', predictions[0]['token_str'])\n",
    "\n",
    "        # Wyświetl wyniki\n",
    "        print(f\"Input Sentence: {sentence}\")\n",
    "        print(f\"Generated Prediction: {predictions[0]['token_str']}\")\n",
    "        print(f\"Predicted Sentence: {completed_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test XML RoBERTa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Pies to najlepszy <mask> człowieka.\n",
      "Generated Prediction: przyjaciel\n",
      "Predicted Sentence: Pies to najlepszy przyjaciel człowieka.\n",
      "\n",
      "Input Sentence: Widzę na niebie kolorową <mask>.\n",
      "Generated Prediction: wodę\n",
      "Predicted Sentence: Widzę na niebie kolorową wodę.\n",
      "\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Jednak mój brat nie zbił <mask> w samochodzie.\n",
      "Generated Prediction: się\n",
      "Predicted Sentence: Jednak mój brat nie zbił się w samochodzie.\n",
      "\n",
      "Input Sentence: Ta ksiązka nalezy do <mask>.\n",
      "Generated Prediction: mnie\n",
      "Predicted Sentence: Ta ksiązka nalezy do mnie.\n",
      "\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Sprzedałam mój rower młodszemu <mask>.\n",
      "Generated Prediction: dziecku\n",
      "Predicted Sentence: Sprzedałam mój rower młodszemu dziecku.\n",
      "\n",
      "Input Sentence: Fajnie jest pomagać <mask> w potrzebie.\n",
      "Generated Prediction: innym\n",
      "Predicted Sentence: Fajnie jest pomagać innym w potrzebie.\n",
      "\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Widzę wysokie <mask> na horyzoncie.\n",
      "Generated Prediction: słońce\n",
      "Predicted Sentence: Widzę wysokie słońce na horyzoncie.\n",
      "\n",
      "Input Sentence: Uwielabim, gdy moja mama przygotowuje <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: Uwielabim, gdy moja mama przygotowuje ..\n",
      "\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Ostatnio częściej zdarza mi się pisać kolorowym <mask>.\n",
      "Generated Prediction: stylu\n",
      "Predicted Sentence: Ostatnio częściej zdarza mi się pisać kolorowym stylu.\n",
      "\n",
      "Input Sentence: Najchętniej jezdzę do szkoły <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: Najchętniej jezdzę do szkoły ..\n",
      "\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Nie mogę przestać marzyć o <mask>.\n",
      "Generated Prediction: życiu\n",
      "Predicted Sentence: Nie mogę przestać marzyć o życiu.\n",
      "\n",
      "Input Sentence: Bardzo długo toczyły się rozmowy o <mask>.\n",
      "Generated Prediction: współpracy\n",
      "Predicted Sentence: Bardzo długo toczyły się rozmowy o współpracy.\n",
      "\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Ej <mask>, o której wrócisz?\n",
      "Generated Prediction: da\n",
      "Predicted Sentence: Ej da, o której wrócisz?\n",
      "\n",
      "Input Sentence: Bądź ostrozny na drodze, <mask>.\n",
      "Generated Prediction: a\n",
      "Predicted Sentence: Bądź ostrozny na drodze, a.\n",
      "\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "for case in cases:\n",
    "    test_cases1(xlm, case)\n",
    "    print(40 * \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test HerBERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Pies to najlepszy <mask> człowieka.\n",
      "Generated Prediction: przyjaciel\n",
      "Predicted Sentence: Pies to najlepszy przyjaciel człowieka.\n",
      "\n",
      "Input Sentence: Widzę na niebie kolorową <mask>.\n",
      "Generated Prediction: gwiazdę\n",
      "Predicted Sentence: Widzę na niebie kolorową gwiazdę.\n",
      "\n",
      "________________________________________\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Jednak mój brat nie zbił <mask> w samochodzie.\n",
      "Generated Prediction: szyby\n",
      "Predicted Sentence: Jednak mój brat nie zbił szyby w samochodzie.\n",
      "\n",
      "Input Sentence: Ta ksiązka nalezy do <mask>.\n",
      "Generated Prediction: mnie\n",
      "Predicted Sentence: Ta ksiązka nalezy do mnie.\n",
      "\n",
      "________________________________________\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Sprzedałam mój rower młodszemu <mask>.\n",
      "Generated Prediction: koledze\n",
      "Predicted Sentence: Sprzedałam mój rower młodszemu koledze.\n",
      "\n",
      "Input Sentence: Fajnie jest pomagać <mask> w potrzebie.\n",
      "Generated Prediction: ludziom\n",
      "Predicted Sentence: Fajnie jest pomagać ludziom w potrzebie.\n",
      "\n",
      "________________________________________\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Widzę wysokie <mask> na horyzoncie.\n",
      "Generated Prediction: góry\n",
      "Predicted Sentence: Widzę wysokie góry na horyzoncie.\n",
      "\n",
      "Input Sentence: Uwielabim, gdy moja mama przygotowuje <mask>.\n",
      "Generated Prediction: obiad\n",
      "Predicted Sentence: Uwielabim, gdy moja mama przygotowuje obiad.\n",
      "\n",
      "________________________________________\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Ostatnio częściej zdarza mi się pisać kolorowym <mask>.\n",
      "Generated Prediction: pismem\n",
      "Predicted Sentence: Ostatnio częściej zdarza mi się pisać kolorowym pismem.\n",
      "\n",
      "Input Sentence: Najchętniej jezdzę do szkoły <mask>.\n",
      "Generated Prediction: autobusem\n",
      "Predicted Sentence: Najchętniej jezdzę do szkoły autobusem.\n",
      "\n",
      "________________________________________\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Nie mogę przestać marzyć o <mask>.\n",
      "Generated Prediction: przyszłości\n",
      "Predicted Sentence: Nie mogę przestać marzyć o przyszłości.\n",
      "\n",
      "Input Sentence: Bardzo długo toczyły się rozmowy o <mask>.\n",
      "Generated Prediction: współpracy\n",
      "Predicted Sentence: Bardzo długo toczyły się rozmowy o współpracy.\n",
      "\n",
      "________________________________________\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Ej <mask>, o której wrócisz?\n",
      "Generated Prediction: ty\n",
      "Predicted Sentence: Ej ty, o której wrócisz?\n",
      "\n",
      "Input Sentence: Bądź ostrozny na drodze, <mask>.\n",
      "Generated Prediction: człowieku\n",
      "Predicted Sentence: Bądź ostrozny na drodze, człowieku.\n",
      "\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "for case in cases:\n",
    "    test_cases1(herbert, case)\n",
    "    print(40 * \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example sentences in different cases for papuGaPT2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominative_papuga =  \"Widzę na niebie kolorową\"\n",
    "\n",
    "genitive_papuga =  \"Ta ksiązka nalezy do\"\n",
    "\n",
    "dative_papuga = \"Sprzedał swój rower młodszemu\"\n",
    "\n",
    "accusative_papuga = \"Uwielabim, gdy moja mama przygotowuje\"\n",
    "\n",
    "instrumental_papuga = \"Właśnie pisze kolorowym\"\n",
    "\n",
    "locative_papuga = \"Nie mogę przestać marzyć o\"\n",
    "\n",
    "vocative_papuga = \"Bądź ostrozny na drodze,\"\n",
    "\n",
    "cases_papuga = [nominative_papuga, genitive_papuga, dative_papuga, accusative_papuga, instrumental_papuga, locative_papuga, vocative_papuga]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominative_papuga2 =  \"Dopiero skończyła się straszna burza. Przestało padać, więc wyszłam na zewnątrz. Widzę na niebie kolorową\"\n",
    "\n",
    "genitive_papuga2 =  \"W tamtym tygodniu zrobił porządki w pokoju. Znalazł wiele ciekawych rzeczy, o których nie miał pojęcia. Ta ksiązka nalezy do\"\n",
    "\n",
    "dative_papuga2 = \"Przez rok mój brat sporo urósł i jego rower juz na niego nie pasuje. Dlatego sprzedałał swój rower młodszemu\"\n",
    "\n",
    "accusative_papuga2 = \"Jestem bardzo leniwa i nienawidzę robiś sobie jedzenia. Poza tym beznadziejnie gotuję. Uwielabim, gdy moja mama przygotowuje\"\n",
    "\n",
    "instrumental_papuga2 = \"Niedawno załozył pamiętnik, w którym notuje swoje przezycia w ciągu dnia. Właśnie pisze kolorowym\"\n",
    "\n",
    "locative_papuga2 = \"Mam dość szkoły. Ciągle tylko testy i kartkówki. Nie mogę przestać marzyć o\"\n",
    "\n",
    "vocative_papuga2 = \"Wiem, ze wybeirasz się w dłuzszą trasę. Bądź ostrozny na drodze,\"\n",
    "\n",
    "cases_papuga2 = [nominative_papuga2, genitive_papuga2, dative_papuga2, accusative_papuga2, instrumental_papuga2, locative_papuga2, vocative_papuga2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cases_papuga(sentences):\n",
    "    model = AutoModelWithLMHead.from_pretrained(papuga)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(papuga)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "        attention_mask = torch.ones(input_ids.shape, device=input_ids.device)\n",
    "\n",
    "        sample_outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            do_sample=True,\n",
    "            max_length=50,\n",
    "            top_k=1,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        print(\"Output:\" + 100 * '-')\n",
    "        for i, sample_output in enumerate(sample_outputs):\n",
    "            print(\"Input sentence: {} \\nGenerated prediction: {}\".format(sentence, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Widzę na niebie kolorową \n",
      "Generated prediction: Widzę na niebie kolorową gwiazdę, która świeci na niebie. W tym momencie, gdy słońce jest nisko, gwiazdy świecą na niebie.\n",
      "W tym momencie, gdy słońce jest nisko, gwiazdy świecą na niebie. W tym momencie, gdy słońce jest nisko,\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Ta ksiązka nalezy do \n",
      "Generated prediction: Ta ksiązka nalezy do gatunku literatury popularnonaukowej, która w sposób przystępny i zrozumiały przedstawia zagadnienia związane z budową i funkcjonowaniem organizmu człowieka.\n",
      "Książka jest przeznaczona dla osób, które chcą poznać budowę i funkcjonowanie organizmu człowieka, a także dla tych, którzy chcą\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Sprzedałam mój rower młodszemu \n",
      "Generated prediction: Sprzedałam mój rower młodszemu bratu, który jest bardzo zadowolony z tego, że ma go już prawie rok.\n",
      "W tym roku postanowiłam, że będę jeździć na rowerze, który jest dla mnie bardzo ważny. Nie wyobrażam sobie, że mogłabym jeździć\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Uwielabim, gdy moja mama przygotowuje \n",
      "Generated prediction: Uwielabim, gdy moja mama przygotowuje się do porodu. Nie wiem, czy to kwestia tego, że jestem w ciąży, czy może po prostu nie mam czasu na to, by się tym zająć.\n",
      "W każdym razie, gdy tylko zobaczyłam\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Właśnie piszę kolorowym \n",
      "Generated prediction: Właśnie piszę kolorowym ołówkiem, ale nie mam pojęcia, jak to zrobić. Czy ktoś może mi pomóc?\n",
      "Witam, mam problem z moim laptopem. Otóż po włączeniu laptopa, po kilku sekundach, laptop się wyłącza, a po kilku sekundach, po\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Nie mogę przestać marzyć o \n",
      "Generated prediction: Nie mogę przestać marzyć o tym, by w końcu móc się z kimś spotkać. Nie mogę przestać myśleć o tym, że to już nie będzie to samo.\n",
      "Nie mogę przestać myśleć o tym, że to już nie będzie to samo. Nie mogę\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Bądź ostrozny na drodze, \n",
      "Generated prediction: Bądź ostrozny na drodze, ale nie daj się wyprzedzić. Nie daj się wyprzedzić, ale nie daj się wyprzedzić.\n",
      "Nie daj się wyprzedzić, ale nie daj się wyprzedzić. Nie daj się wyprzedzić, ale nie daj się\n"
     ]
    }
   ],
   "source": [
    "test_cases_papuga(cases_papuga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Dopiero skończyła się straszna burza. Przestało padać, więc wyszłam na zewnątrz. Widzę na niebie kolorową \n",
      "Generated prediction: Dopiero skończyła się straszna burza. Przestało padać, więc wyszłam na zewnątrz. Widzę na niebie kolorową chmurę. Jest to znak, że zbliża się burza.\n",
      "Wstałam i poszłam do domu. W domu było już ciemno. W\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: W tamtym tygodniu zrobił porządki w pokoju. Znalazł wiele ciekawych rzeczy, o których nie miał pojęcia. Ta ksiązka nalezy do \n",
      "Generated prediction: W tamtym tygodniu zrobił porządki w pokoju. Znalazł wiele ciekawych rzeczy, o których nie miał pojęcia. Ta ksiązka nalezy do jego ulubionych.\n",
      "W tym tygodniu zrobił porządki w pokoju. Znalazł wiele ciekawych rzeczy, o których nie miał pojęcia. Ta\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Przez rok mój brat sporo urósł i jego rower juz na niego nie pasuje. Dlatego sprzedałał swój rower młodszemu \n",
      "Generated prediction: Przez rok mój brat sporo urósł i jego rower juz na niego nie pasuje. Dlatego sprzedałał swój rower młodszemu bratu.\n",
      "Ja też mam rower, ale nie wiem czy jest sens go sprzedawać. Ja mam rower z silnikiem i nie wiem\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Jestem bardzo leniwa i nienawidzę robiś sobie jedzenia. Poza tym beznadziejnie gotuję. Uwielabim, gdy moja mama przygotowuje \n",
      "Generated prediction: Jestem bardzo leniwa i nienawidzę robiś sobie jedzenia. Poza tym beznadziejnie gotuję. Uwielabim, gdy moja mama przygotowuje obiad.\n",
      "Nienawidzę gotować. Nienawidzę gotować. Nienawidzę gotować. Nienawidzę\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Niedawno załozył pamiętnik, w którym notuje swoje przezycia w ciągu dnia. Właśnie pisze kolorowym \n",
      "Generated prediction: Niedawno załozył pamiętnik, w którym notuje swoje przezycia w ciągu dnia. Właśnie pisze kolorowym ołówkiem, że jest w stanie wojny, że jest w stanie wojny, że jest w stanie wojny, że jest w stanie wojny, że\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Mam dość szkoły. Ciągle tylko testy i kartkówki. Nie mogę przestać marzyć o \n",
      "Generated prediction: Mam dość szkoły. Ciągle tylko testy i kartkówki. Nie mogę przestać marzyć o tym, żeby zostać lekarzem.\n",
      "W szkole nie ma czasu na nudę. Nie ma czasu na nudę. Nie ma czasu na nudę. Nie ma czasu\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Wiem, ze wybeirasz się w dłuzszą trasę. Bądź ostrozny na drodze, \n",
      "Generated prediction: Wiem, ze wybeirasz się w dłuzszą trasę. Bądź ostrozny na drodze, bo może się okazać, że nie zdążysz na czas.\n",
      "W tym roku w tym roku nie ma śniegu, ale w tym roku jest bardzo ciepło\n"
     ]
    }
   ],
   "source": [
    "test_cases_papuga(cases_papuga2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devise a method to test long-range relationships such as gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "masculine = [\n",
    "    \"Szef wziął swój notes i <mask> na spotkanie z klientem.\", \"Mój ojciec zawsze <mask> naprawić zepsute sprzęty, ale tym razem nie dał rady,\", \"On przeczytał ksiązkę, po czym <mask>.\"]\n",
    "feminine = [\"Jego dziewczyna <mask> przez okno i stwierdziła, ze pora wyjść.\", \"Jakiś czas temu <mask> udział w ciekawym przedsięwzięciu, które potem pozwoliło jej otworzyć swój własny biznes.\", \"Ich córka najpierw bawiła się na placu zabaw, odpoczywała, a potem <mask>.\"]\n",
    "neuter = [\"Dziecko weszło do autobusu, <mask> kanapkę i wypiło sok.\", \"Nasze nowe auto <mask> w garazu.\", \"Koło najpierw się toczyło, a później <mask>.\"]\n",
    "\n",
    "\n",
    "genders = [masculine, feminine, neuter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Szef wziął swój notes i <mask> na spotkanie z klientem.\n",
      "Generated Prediction: wpadł\n",
      "Predicted Sentence: Szef wziął swój notes i wpadł na spotkanie z klientem.\n",
      "\n",
      "Input Sentence: Mój ojciec zawsze <mask> naprawić zepsute sprzęty, ale tym razem nie dał rady,\n",
      "Generated Prediction: próbował\n",
      "Predicted Sentence: Mój ojciec zawsze próbował naprawić zepsute sprzęty, ale tym razem nie dał rady,\n",
      "\n",
      "Input Sentence: On przeczytał ksiązkę, po czym <mask>.\n",
      "Generated Prediction: napisał\n",
      "Predicted Sentence: On przeczytał ksiązkę, po czym napisał.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Jego dziewczyna <mask> przez okno i stwierdziła, ze pora wyjść.\n",
      "Generated Prediction: była\n",
      "Predicted Sentence: Jego dziewczyna była przez okno i stwierdziła, ze pora wyjść.\n",
      "\n",
      "Input Sentence: Jakiś czas temu <mask> udział w ciekawym przedsięwzięciu, które potem pozwoliło jej otworzyć swój własny biznes.\n",
      "Generated Prediction: bierze\n",
      "Predicted Sentence: Jakiś czas temu bierze udział w ciekawym przedsięwzięciu, które potem pozwoliło jej otworzyć swój własny biznes.\n",
      "\n",
      "Input Sentence: Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem <mask>.\n",
      "Generated Prediction: ...\n",
      "Predicted Sentence: Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem ....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Dziecko weszło do autobusu, <mask> kanapkę i wypiło sok.\n",
      "Generated Prediction: zostało\n",
      "Predicted Sentence: Dziecko weszło do autobusu, zostało kanapkę i wypiło sok.\n",
      "\n",
      "Input Sentence: Nasze nowe auto <mask> w garazu.\n",
      "Generated Prediction: jest\n",
      "Predicted Sentence: Nasze nowe auto jest w garazu.\n",
      "\n",
      "Input Sentence: Koło najpierw się toczyło, a później <mask>.\n",
      "Generated Prediction: ...\n",
      "Predicted Sentence: Koło najpierw się toczyło, a później ....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gender in genders:\n",
    "    test_cases1(xlm, gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Szef wziął swój notes i <mask> na spotkanie z klientem.\n",
      "Generated Prediction: poszedł\n",
      "Predicted Sentence: Szef wziął swój notes i poszedł na spotkanie z klientem.\n",
      "\n",
      "Input Sentence: Mój ojciec zawsze <mask> naprawić zepsute sprzęty, ale tym razem nie dał rady,\n",
      "Generated Prediction: próbował\n",
      "Predicted Sentence: Mój ojciec zawsze próbował naprawić zepsute sprzęty, ale tym razem nie dał rady,\n",
      "\n",
      "Input Sentence: On przeczytał ksiązkę, po czym <mask>.\n",
      "Generated Prediction: wyszedł\n",
      "Predicted Sentence: On przeczytał ksiązkę, po czym wyszedł.\n",
      "\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Jego dziewczyna <mask> przez okno i stwierdziła, ze pora wyjść.\n",
      "Generated Prediction: wyszła\n",
      "Predicted Sentence: Jego dziewczyna wyszła przez okno i stwierdziła, ze pora wyjść.\n",
      "\n",
      "Input Sentence: Jakiś czas temu <mask> udział w ciekawym przedsięwzięciu, które potem pozwoliło jej otworzyć swój własny biznes.\n",
      "Generated Prediction: wzięła\n",
      "Predicted Sentence: Jakiś czas temu wzięła udział w ciekawym przedsięwzięciu, które potem pozwoliło jej otworzyć swój własny biznes.\n",
      "\n",
      "Input Sentence: Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem <mask>.\n",
      "Generated Prediction: chodziła\n",
      "Predicted Sentence: Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem chodziła.\n",
      "\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Dziecko weszło do autobusu, <mask> kanapkę i wypiło sok.\n",
      "Generated Prediction: zrobiło\n",
      "Predicted Sentence: Dziecko weszło do autobusu, zrobiło kanapkę i wypiło sok.\n",
      "\n",
      "Input Sentence: Nasze nowe auto <mask> w garazu.\n",
      "Generated Prediction: czeka\n",
      "Predicted Sentence: Nasze nowe auto czeka w garazu.\n",
      "\n",
      "Input Sentence: Koło najpierw się toczyło, a później <mask>.\n",
      "Generated Prediction: rosło\n",
      "Predicted Sentence: Koło najpierw się toczyło, a później rosło.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gender in genders:\n",
    "    test_cases1(herbert, gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "masculine_papuga = \"On przeczytał ksiązkę, po czym\"\n",
    "feminine_papuga = \"Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem\"\n",
    "neuter_papuga = \"Koło najpierw się toczyło, a później\"\n",
    "\n",
    "\n",
    "genders_papuga = [masculine_papuga, feminine_papuga, neuter_papuga]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: On przeczytał ksiązkę, po czym \n",
      "Generated prediction: On przeczytał ksiązkę, po czym zaczął się śmiać.\n",
      "- Nie, nie, nie.\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem \n",
      "Generated prediction: Ich córka najpierw bawiła się na placu zabaw, odpoczytwała, a potem poszła do szkoły.\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Koło najpierw się toczyło, a później \n",
      "Generated prediction: Koło najpierw się toczyło, a później się toczyło.\n",
      "- Nie, nie, nie.\n"
     ]
    }
   ],
   "source": [
    "test_cases_papuga(genders_papuga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the model captures real-world knolwedge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge = [\n",
    "    \"Druga wojna światowa rozpoczęła się w <mask> roku.\", #1939\n",
    "    \"<mask> jest stolicą Unii Europejskiej.\", #Bruksela\n",
    "    \"Woda ma maksymalną gęstość przy temperaturze <mask> stopni Celsjusza.\", #4\n",
    "    \"Góra o nazwie <mask> jest najwyższym szczytem w systemie górskim Himalajów.\" #Everest\n",
    "]\n",
    "knowledges = [knowledge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: Druga wojna światowa rozpoczęła się w <mask> roku.\n",
      "Generated Prediction: 1939\n",
      "Predicted Sentence: Druga wojna światowa rozpoczęła się w 1939 roku.\n",
      "\n",
      "Input Sentence: <mask> jest stolicą Unii Europejskiej.\n",
      "Generated Prediction: Bruksela\n",
      "Predicted Sentence: Bruksela jest stolicą Unii Europejskiej.\n",
      "\n",
      "Input Sentence: Woda ma maksymalną gęstość przy temperaturze <mask> stopni Celsjusza.\n",
      "Generated Prediction: 30\n",
      "Predicted Sentence: Woda ma maksymalną gęstość przy temperaturze 30 stopni Celsjusza.\n",
      "\n",
      "Input Sentence: Góra o nazwie <mask> jest najwyższym szczytem w systemie górskim Himalajów.\n",
      "Generated Prediction: Ta\n",
      "Predicted Sentence: Góra o nazwie Ta jest najwyższym szczytem w systemie górskim Himalajów.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in knowledges:\n",
    "    test_cases1(\"allegro/herbert-base-cased\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: Druga wojna światowa rozpoczęła się w <mask> roku.\n",
      "Generated Prediction: 1939\n",
      "Predicted Sentence: Druga wojna światowa rozpoczęła się w 1939 roku.\n",
      "\n",
      "Input Sentence: <mask> jest stolicą Unii Europejskiej.\n",
      "Generated Prediction: Polska\n",
      "Predicted Sentence: Polska jest stolicą Unii Europejskiej.\n",
      "\n",
      "Input Sentence: Woda ma maksymalną gęstość przy temperaturze <mask> stopni Celsjusza.\n",
      "Generated Prediction: 25\n",
      "Predicted Sentence: Woda ma maksymalną gęstość przy temperaturze 25 stopni Celsjusza.\n",
      "\n",
      "Input Sentence: Góra o nazwie <mask> jest najwyższym szczytem w systemie górskim Himalajów.\n",
      "Generated Prediction: Everest\n",
      "Predicted Sentence: Góra o nazwie Everest jest najwyższym szczytem w systemie górskim Himalajów.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in knowledges:\n",
    "    test_cases1(\"xlm-roberta-base\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_papuga = [\n",
    "    \"Druga wojna światowa rozpoczęła się w roku\", #1939\n",
    "    \"Stolicą Unii Europejskiej jest\", #Bruksela\n",
    "    \"Woda ma maksymalną gęstość w temperaturze o wartości\", #4\n",
    "    \"Najwyzszym szczytem w systemie górskim Himalajów jest\" #Everest\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Druga wojna światowa rozpoczęła się w roku \n",
      "Generated prediction: Druga wojna światowa rozpoczęła się w roku 1914. W tym czasie w Europie i na świecie zapanowała epi\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Stolicą Unii Europejskiej jest \n",
      "Generated prediction: Stolicą Unii Europejskiej jest Luksemburg. W tym kraju, w którym w latach 90. XX\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Woda ma maksymalną gęstość w temperaturze o wartości \n",
      "Generated prediction: Woda ma maksymalną gęstość w temperaturze o wartości około 10°C. W przypadku, gdy temperatura otoczenia jest\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: Najwyzszym szczytem w systemie górskim Himalajów jest \n",
      "Generated prediction: Najwyzszym szczytem w systemie górskim Himalajów jest Pik Pobiedy (8157 m\n"
     ]
    }
   ],
   "source": [
    "test_cases_papuga(knowledge_papuga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check zero-shot learning capabilites of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_negative = [\"'Jak ja go nie lubię.' Zdanie to ma <mask> wydźwięk\", \"'Pogoda dzisiaj jest beznadziejna.' Zdanie to ma wydźwięk <mask>\", \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie <mask>\"]\n",
    "sentiment_positive = [\"'To jest mój ulubiony serial!' Zdanie to ma wydźwięk <mask>.\", \"'Jak ładnie dzisiaj jest na dworze!' Zdanie to ma wydźwięk <mask>.\", \"'Zycie jest takie piękne!' Zdanie to ma wydźwięk <mask>.\"]\n",
    "\n",
    "sentiments = [sentiment_negative, sentiment_positive]\n",
    "\n",
    "sentiment_negative2 = [\"'Jak ja go nie lubię.' Zdanie to jest nacechowane <mask>.\", \"'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane <mask>.\", \"'Nic mi się nie chce!' Zdanie to jest nacechowane <mask>.\"]\n",
    "sentiment_positive2 = [\"'To jest mój ulubiony serial!' Zdanie to jest nacechowane <mask>.\", \"'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane <mask>.\", \"'Zycie jest takie piękne!' Zdanie to jest nacechowane <mask>.\"]\n",
    "\n",
    "sentiments2 = [sentiment_negative2, sentiment_positive2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: 'Jak ja go nie lubię.' Zdanie to ma <mask> wydźwięk\n",
      "Generated Prediction: swój\n",
      "Predicted Sentence: 'Jak ja go nie lubię.' Zdanie to ma swój wydźwięk\n",
      "\n",
      "Input Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to ma wydźwięk <mask>\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to ma wydźwięk .\n",
      "\n",
      "Input Sentence: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie <mask>\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: 'To jest mój ulubiony serial!' Zdanie to ma wydźwięk <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'To jest mój ulubiony serial!' Zdanie to ma wydźwięk ..\n",
      "\n",
      "Input Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to ma wydźwięk <mask>.\n",
      "Generated Prediction: nąć\n",
      "Predicted Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to ma wydźwięk nąć.\n",
      "\n",
      "Input Sentence: 'Zycie jest takie piękne!' Zdanie to ma wydźwięk <mask>.\n",
      "Generated Prediction: nąć\n",
      "Predicted Sentence: 'Zycie jest takie piękne!' Zdanie to ma wydźwięk nąć.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentiments:\n",
    "    test_cases1(xlm, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: 'Jak ja go nie lubię.' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Jak ja go nie lubię.' Zdanie to jest nacechowane ..\n",
      "\n",
      "Input Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane ..\n",
      "\n",
      "Input Sentence: 'Nic mi się nie chce!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Nic mi się nie chce!' Zdanie to jest nacechowane ..\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing xlm-roberta-base:\n",
      "\n",
      "Input Sentence: 'To jest mój ulubiony serial!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'To jest mój ulubiony serial!' Zdanie to jest nacechowane ..\n",
      "\n",
      "Input Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane ..\n",
      "\n",
      "Input Sentence: 'Zycie jest takie piękne!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Zycie jest takie piękne!' Zdanie to jest nacechowane ..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentiments2:\n",
    "    test_cases1(xlm, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: 'Jak ja go nie lubię.' Zdanie to ma <mask> wydźwięk\n",
      "Generated Prediction: swój\n",
      "Predicted Sentence: 'Jak ja go nie lubię.' Zdanie to ma swój wydźwięk\n",
      "\n",
      "Input Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to ma wydźwięk <mask>\n",
      "Generated Prediction: :\n",
      "Predicted Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to ma wydźwięk :\n",
      "\n",
      "Input Sentence: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie <mask>\n",
      "Generated Prediction: .\n",
      "Predicted Sentence: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie .\n",
      "\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: 'To jest mój ulubiony serial!' Zdanie to ma wydźwięk <mask>.\n",
      "Generated Prediction: polityczny\n",
      "Predicted Sentence: 'To jest mój ulubiony serial!' Zdanie to ma wydźwięk polityczny.\n",
      "\n",
      "Input Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to ma wydźwięk <mask>.\n",
      "Generated Prediction: symboliczny\n",
      "Predicted Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to ma wydźwięk symboliczny.\n",
      "\n",
      "Input Sentence: 'Zycie jest takie piękne!' Zdanie to ma wydźwięk <mask>.\n",
      "Generated Prediction: symboliczny\n",
      "Predicted Sentence: 'Zycie jest takie piękne!' Zdanie to ma wydźwięk symboliczny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentiments:\n",
    "    test_cases1(herbert, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: 'Jak ja go nie lubię.' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: negatywnie\n",
      "Predicted Sentence: 'Jak ja go nie lubię.' Zdanie to jest nacechowane negatywnie.\n",
      "\n",
      "Input Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: smutkiem\n",
      "Predicted Sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane smutkiem.\n",
      "\n",
      "Input Sentence: 'Nic mi się nie chce!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: smutkiem\n",
      "Predicted Sentence: 'Nic mi się nie chce!' Zdanie to jest nacechowane smutkiem.\n",
      "\n",
      "Testing allegro/herbert-base-cased:\n",
      "\n",
      "Input Sentence: 'To jest mój ulubiony serial!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: emocjami\n",
      "Predicted Sentence: 'To jest mój ulubiony serial!' Zdanie to jest nacechowane emocjami.\n",
      "\n",
      "Input Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: optymizmem\n",
      "Predicted Sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane optymizmem.\n",
      "\n",
      "Input Sentence: 'Zycie jest takie piękne!' Zdanie to jest nacechowane <mask>.\n",
      "Generated Prediction: optymizmem\n",
      "Predicted Sentence: 'Zycie jest takie piękne!' Zdanie to jest nacechowane optymizmem.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentiments2:\n",
    "    test_cases1(herbert, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_negative2_papuga = [\"'Jak ja go nie lubię.' Zdanie to jest nacechowane\", \"'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane\", \"'Nic mi się nie chce!' Zdanie to jest nacechowana\"]\n",
    "sentiment_positive2_papuga = [\"'To jest mój ulubiony serial!' Zdanie to jest nacechowane\", \"'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane\", \"'Zycie jest piękne!' Zdanie to jest nacechowane\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: 'Jak ja go nie lubię.' Zdanie to jest nacechowane \n",
      "Generated prediction: 'Jak ja go nie lubię.' Zdanie to jest nacechowane ironią, ale nie jest to też zdanie, które można by uznać za obraźliwe.\n",
      "- Nie, nie, nie. Nie, nie. Nie, nie.\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane \n",
      "Generated prediction: 'Pogoda dzisiaj jest beznadziejna.' Zdanie to jest nacechowane negatywnie.'\n",
      "''W tym roku nie ma śniegu, a w tym roku jest bardzo zimno.' - powiedział.' - 'Nie ma śniegu, jest zimno\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: 'Nic mi się nie chce!' Zdanie to jest nacechowana \n",
      "Generated prediction: 'Nic mi się nie chce!' Zdanie to jest nacechowana ironią, ale nie jest to też nacechowane negatywnie.\n",
      "- Nie, nie, nie, nie. Nie, nie. Nie, nie. Nie,\n"
     ]
    }
   ],
   "source": [
    "test_cases_papuga(sentiment_negative2_papuga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: 'To jest mój ulubiony serial!' Zdanie to jest nacechowane \n",
      "Generated prediction: 'To jest mój ulubiony serial!' Zdanie to jest nacechowane bardzo emocjonalnie, ale nie jest to też serial, który ogląda się z przyjemnością.\n",
      "'To jest mój ulubiony serial!' Zdanie to jest nacechowane bardzo\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane \n",
      "Generated prediction: 'Jak ładnie dzisiaj jest na dworze!' Zdanie to jest nacechowane bardzo optymistycznie, a zarazem jest to zdanie, które może być bardzo przydatne w życiu.\n",
      "'Jak pięknie jest na dworze!' Zdanie to jest nace\n",
      "Output:----------------------------------------------------------------------------------------------------\n",
      "Input sentence: 'Zycie jest piękne!' Zdanie to jest nacechowane \n",
      "Generated prediction: 'Zycie jest piękne!' Zdanie to jest nacechowane szacunkiem i miłością do ludzi, którzy są dla nas ważni.\n",
      "\"Nie ma nic piękniejszego niż uśmiech dziecka, który jest najpiękniejszy na świecie. Uśmiech dziecka jest najpięk\n"
     ]
    }
   ],
   "source": [
    "test_cases_papuga(sentiment_positive2_papuga)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16323c91b843e809beaa456fc31b90062c2b6877cc09dc9168e9867538bda6d2"
  },
  "kernelspec": {
   "display_name": "Python 3.11.6 ('PJN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
